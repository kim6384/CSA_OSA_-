{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e533be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import librosa.display\n",
    "#mne의 time_frequency 또는 librosa는 오류가 있어 scipy를 사용함. 200203\n",
    "from scipy import signal\n",
    "#import random\n",
    "import mne\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import scipy.stats as ss\n",
    "from scipy import signal\n",
    "MITmon_matrix7=[-1,'T7-FT9',-1,-1,'FP1-F7','F7-T7','T7-P7','P7-O1','FP1-F3','F3-C3','C3-P3','P3-O1',-1,'FZ-CZ','CZ-PZ',-1,\n",
    "                'FP2-F4', 'F4-C4','C4-P4','P4-O2','FP2-F8','F8-T8','T8-P8','P8-O2', -1,'FT10-T8', -1, -1]\n",
    "## FT9, FT10 체널 빠진 부분 0으로 대체. 13번 환자에서 특히 많았음.\n",
    "\n",
    "channel_order_list=['T7-FT9','FP1-F7','F7-T7','T7-P7','P7-O1','FP1-F3','F3-C3','C3-P3','P3-O1','FZ-CZ','CZ-PZ',\n",
    "                'FP2-F4', 'F4-C4','C4-P4','P4-O2','FP2-F8','F8-T8','T8-P8-0','P8-O2', 'FT10-T8']#T8-P8이 2개가 있어, MNE에서 불러올때 -0 -1 꼬리표 붙음\n",
    "\n",
    "Mon_matrix=MITmon_matrix7\n",
    "Mon_matrix_col_no=7 # 7 또는 5 중 7으로 진행.\n",
    "Mon_matrix_row_no=4 #row는 4로 고정\n",
    "\n",
    "sampling_rate=200 #MIT는 256, SNUH는 200\n",
    "freq_seg=0.5 #freq domain 기본 간격\n",
    "freq_total_n=sampling_rate/freq_seg # freq domain 간격 총 개수\n",
    "freq_upper_range=40 #freq upper range Hz\n",
    "freq_n=int(freq_upper_range/freq_seg) #일단 현재는 40\n",
    "sec_frame=20 #LSTM의 frame 길이\n",
    "edf_list = os.listdir('edf_file/')\n",
    "make_ch_list=['FP1-F7','F7-T3','T3-T1','T3-T5','T5-O1','FP1-F3','F3-C3','FZ-CZ','C3-P3','P3-O1','FP2-F4','F4-C4','CZ-PZ','C4-P4','P4-O2',\n",
    "'FP2-F8','F8-T4','T4-T2','T4-T6','T6-O2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf8a915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#edf_list = os.listdir('edf_file/')\n",
    "for order in range(0,len(edf_list)):\n",
    "    freq_dict = {}\n",
    "    sampling_rate = 200\n",
    "    raw = mne.io.read_raw_edf('edf_file' +'/'+ edf_list[order], preload=True)\n",
    "    raw.filter(l_freq=0.5,h_freq=30)\n",
    "    channel_list=raw.ch_names   \n",
    "    data=raw._data\n",
    "    channel_name_list = []\n",
    "    for ch in range(len(channel_list)):\n",
    "        channel_name_list.append([channel_list[ch].split('-')[0].upper(),ch])\n",
    "    for ma in range(len(make_ch_list)):\n",
    "        odd_list = []\n",
    "        for fr in range(len(channel_name_list)):\n",
    "            for be in range(len(channel_name_list)):\n",
    "                if channel_name_list[fr][0]+str('-')+ channel_name_list[be][0] == make_ch_list[ma]:\n",
    "                    odd_list.append([fr,be])\n",
    "                    #print(ma)\n",
    "                    make_data=data[fr] - data[be]\n",
    "                    f, t, Zxx = signal.stft(make_data,fs=sampling_rate,nperseg=400,noverlap=200,nfft=freq_total_n)\n",
    "                    freq_dict[make_ch_list[ma]] = {}\n",
    "                    Zxx=Zxx.astype('float')\n",
    "                    freq_dict[make_ch_list[ma]]=Zxx[0:int(freq_n),:-1]  \n",
    "                    break\n",
    "    with open('/SNU_data/pickle_file/stft_filter/'+edf_list[order].split('.')[0]+'.pickle', 'wb') as f:\n",
    "        pickle.dump(freq_dict, f, pickle.HIGHEST_PROTOCOL) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fabf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(make_ch_list)):\n",
    "    make_ch_list[i]=make_ch_list[i].upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7050d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "odd_list = []\n",
    "for ma in range(len(make_ch_list)):\n",
    "    for fr in range(len(channel_name_list[:-1])):\n",
    "        for be in range(len(channel_name_list[:-1])):\n",
    "        \n",
    "            if channel_name_list[fr][0]+str('-')+ channel_name_list[be][0] == make_ch_list[ma]:\n",
    "                odd_list.append([fr,be])\n",
    "                print(make_ch_list[ma])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356b3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaec885",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel('SNUH_VEM_200326.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb543942",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_dict = {}\n",
    "for d in range(len(df)):\n",
    "    time_dict[d+1] = {}\n",
    "    s = str(df.iloc[d,:][9]).replace('-','/')\n",
    "    start_time = datetime.strptime(s, \"%Y/%m/%d %H:%M:%S\")      \n",
    "    e = str(df.iloc[d,:][10]).replace('-','/')\n",
    "    end_time = datetime.strptime(e, \"%Y/%m/%d %H:%M:%S\")  \n",
    "    tmin=end_time-start_time \n",
    "    tmin=int(tmin.total_seconds())\n",
    "    time_dict[d+1]['start'] = s\n",
    "    time_dict[d+1]['end'] = e\n",
    "    time_dict[d+1]['time_second'] = tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac84646",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_file/time_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(time_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ff3ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sz_dict = {}\n",
    "for d in range(len(df)):\n",
    "    sz_dict[d+1] = {}\n",
    "    if df.iloc[d,:][7] != 0 :\n",
    "        sz_dict[d+1]['num'] = df.iloc[d,:][7]\n",
    "        for sz in range(int(df.iloc[d,:][7])):\n",
    "            sz_dict[d+1][sz+1] = {}\n",
    "            sz_s =str(df.iloc[d,:][16+(2*sz)]).replace('-','/')\n",
    "            start_time = datetime.strptime(sz_s, \"%Y/%m/%d %H:%M:%S\")      \n",
    "            sz_e =str(df.iloc[d,:][16+(2*sz)+1]).replace('-','/')\n",
    "            end_time = datetime.strptime(sz_e, \"%Y/%m/%d %H:%M:%S\")  \n",
    "            tmin=end_time-start_time \n",
    "            tmin=int(tmin.total_seconds())\n",
    "            sz_dict[d+1][sz+1]['start'] = sz_s\n",
    "            sz_dict[d+1][sz+1]['end'] = sz_e\n",
    "            sz_dict[d+1][sz+1]['time_second'] = tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6d3da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dis_dict = {}\n",
    "for d in range(len(df)):\n",
    "    dis_dict[d+1] = {}\n",
    "    if str(df.iloc[d,:][12]) != 'NaT':    \n",
    "        if str(df.iloc[d,:][14]) != 'NaT':\n",
    "            dis_dict[d+1]['num'] = 2\n",
    "            for dis in range(2):\n",
    "                dis_dict[d+1][dis+1] = {}\n",
    "                dis_s =str(df.iloc[d,:][12+(dis*2)]).replace('-','/')\n",
    "                start_time = datetime.strptime(dis_s, \"%Y/%m/%d %H:%M:%S\")      \n",
    "                dis_e =str(df.iloc[d,:][12+(dis*2)+1]).replace('-','/')\n",
    "                end_time = datetime.strptime(dis_e, \"%Y/%m/%d %H:%M:%S\")  \n",
    "                tmin=end_time-start_time \n",
    "                tmin=int(tmin.total_seconds())\n",
    "                dis_dict[d+1][dis+1]['start'] = dis_s\n",
    "                dis_dict[d+1][dis+1]['end'] = dis_e\n",
    "                dis_dict[d+1][dis+1]['time_second'] = tmin\n",
    "        else:\n",
    "            dis_dict[d+1]['num'] = 1\n",
    "            for dis in range(1):\n",
    "                dis_dict[d+1][dis+1] = {}\n",
    "                dis_s =str(df.iloc[d,:][12+(dis)]).replace('-','/')\n",
    "                start_time = datetime.strptime(dis_s, \"%Y/%m/%d %H:%M:%S\")      \n",
    "                dis_e =str(df.iloc[d,:][12+(dis)+1]).replace('-','/')\n",
    "                end_time = datetime.strptime(dis_e, \"%Y/%m/%d %H:%M:%S\")  \n",
    "                tmin= end_time-start_time \n",
    "                tmin=int(tmin.total_seconds())\n",
    "                dis_dict[d+1][dis+1]['start'] = dis_s\n",
    "                dis_dict[d+1][dis+1]['end'] = dis_e\n",
    "                dis_dict[d+1][dis+1]['time_second'] = tmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1a617b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_file/dis_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(dis_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8ebc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "reoff_dict = {}\n",
    "for d in range(len(df)):\n",
    "    reoff_dict[d+1] = {}\n",
    "    if str(df.iloc[d,:][11]) != 'NaT':     \n",
    "        #reoff_dict[d+1]\n",
    "        reoff_s =str(df.iloc[d,:][11]).replace('-','/')\n",
    "        reoff_time = datetime.strptime(reoff_s, \"%Y/%m/%d %H:%M:%S\")      \n",
    "        start =str(df.iloc[d,:][9]).replace('-','/')\n",
    "        start_time = datetime.strptime(start, \"%Y/%m/%d %H:%M:%S\")  \n",
    "        tmin=reoff_time-start_time \n",
    "        tmin=int(tmin.total_seconds())\n",
    "        reoff_dict[d+1]['start'] = reoff_s        \n",
    "        reoff_dict[d+1]['time_second'] = tmin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7db50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickle_file/reoff_dict.pickle', 'wb') as f:\n",
    "    pickle.dump(reoff_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
